{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99ZqikFXr45N"
      },
      "source": [
        "Tasks to be Done:\n",
        "\n",
        "Using MNIST Dataset try to buildyourConvolutional Neural Network:\n",
        "\n",
        "A. Do some necessary importslike:\n",
        "a. Download the MNIST dataset through Keras\n",
        "b. Import a sequential model\n",
        "c. Import the convolution and pooling layers\n",
        "d. Import dense layers, dropout layer, and the flatten layer\n",
        "e. Import numpy\n",
        "\n",
        "B. Fit the dataset to a model, i.e. train the model for 12 epochs.\n",
        "a. After training the model,evaluate the loss and accuracy of the model on the test\n",
        "data and print it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MQ8AiQbqqfaa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ui5Rn8OArpqh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX_ocIHyr8yg",
        "outputId": "023d4383-daba-4ca8-a947-e51c71512232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Spliting the data and test\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWhgzAbUsi0d",
        "outputId": "a9b1e427-f53d-43d4-ec55-1f4d92be138d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               204928    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 225,034\n",
            "Trainable params: 225,034\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Preprocess the data\n",
        "# Normalize the pixel values to a range between 0 and 1\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Convert the labels to one-hot encoding\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Reshape the input data to fit the CNN input shape\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# Step B: Import a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Step C: Import the convolution and pooling layers\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Add another convolutional and pooling layer for better feature extraction\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Step D: Import dense layers, dropout layer, and the flatten layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Dropout layer to reduce overfitting\n",
        "model.add(Dense(10, activation='softmax'))  # Output layer with 10 units for each class\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print the summary of the model to see its architecture\n",
        "model.summary()\n",
        "\n",
        "# Step E: Import numpy (already done in the import section above)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XIRZaDctRwe",
        "outputId": "cc79d165-c90b-49c8-c4ef-b811bd9eb167"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "300/300 [==============================] - 12s 40ms/step - loss: 0.3768 - accuracy: 0.8848 - val_loss: 0.0750 - val_accuracy: 0.9748\n",
            "Epoch 2/12\n",
            "300/300 [==============================] - 11s 37ms/step - loss: 0.1174 - accuracy: 0.9655 - val_loss: 0.0480 - val_accuracy: 0.9840\n",
            "Epoch 3/12\n",
            "300/300 [==============================] - 10s 35ms/step - loss: 0.0828 - accuracy: 0.9758 - val_loss: 0.0381 - val_accuracy: 0.9870\n",
            "Epoch 4/12\n",
            "300/300 [==============================] - 10s 32ms/step - loss: 0.0688 - accuracy: 0.9799 - val_loss: 0.0387 - val_accuracy: 0.9869\n",
            "Epoch 5/12\n",
            "300/300 [==============================] - 10s 34ms/step - loss: 0.0593 - accuracy: 0.9825 - val_loss: 0.0342 - val_accuracy: 0.9889\n",
            "Epoch 6/12\n",
            "300/300 [==============================] - 11s 36ms/step - loss: 0.0500 - accuracy: 0.9851 - val_loss: 0.0277 - val_accuracy: 0.9912\n",
            "Epoch 7/12\n",
            "300/300 [==============================] - 12s 42ms/step - loss: 0.0453 - accuracy: 0.9867 - val_loss: 0.0254 - val_accuracy: 0.9916\n",
            "Epoch 8/12\n",
            "300/300 [==============================] - 12s 40ms/step - loss: 0.0417 - accuracy: 0.9873 - val_loss: 0.0264 - val_accuracy: 0.9915\n",
            "Epoch 9/12\n",
            "300/300 [==============================] - 11s 38ms/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 0.0246 - val_accuracy: 0.9918\n",
            "Epoch 10/12\n",
            "300/300 [==============================] - 21s 70ms/step - loss: 0.0356 - accuracy: 0.9891 - val_loss: 0.0232 - val_accuracy: 0.9932\n",
            "Epoch 11/12\n",
            "300/300 [==============================] - 24s 80ms/step - loss: 0.0309 - accuracy: 0.9905 - val_loss: 0.0232 - val_accuracy: 0.9925\n",
            "Epoch 12/12\n",
            "300/300 [==============================] - 20s 68ms/step - loss: 0.0298 - accuracy: 0.9908 - val_loss: 0.0230 - val_accuracy: 0.9928\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1feb846aca0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=12, batch_size=200, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CwMYOH5AwUE3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.02299298159778118\n",
            "Test accuracy: 0.9927999973297119\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kVhEWJEqY5q"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
